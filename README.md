# Visual-Question-Answering
This Project involves creating a multiple-choice Visual Question Answering (VQA) dataset using the Amazon Berkeley Objects (ABO) dataset, evaluating baseline models, fine-tuning using Low-Rank Adaptation (LoRA), and assessing performance using standard metrics. 

Please refer to the report.pdf file for more details about the models, files, steps followed and the final results of the project. 
