{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11472097,"sourceType":"datasetVersion","datasetId":7189537},{"sourceId":11576630,"sourceType":"datasetVersion","datasetId":7258395},{"sourceId":11641302,"sourceType":"datasetVersion","datasetId":7304749}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import google.generativeai as genai\n\ngenai.configure(api_key=\"API-KEY\") #replace this with your gemini API key\n\nmodel = genai.GenerativeModel(\"gemini-1.5-flash\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\nmetadata_path = \"path to image input directory\" #replace with the path of the file where we have the images \ndf = pd.read_csv(metadata_path)\ndf.head()\nprint(\"Total images:\", len(df))\n\nimage_base_path = \"path for the small directory in the abo-small dataset\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:57:11.905841Z","iopub.execute_input":"2025-05-04T16:57:11.906521Z","iopub.status.idle":"2025-05-04T16:57:12.419442Z","shell.execute_reply.started":"2025-05-04T16:57:11.906493Z","shell.execute_reply":"2025-05-04T16:57:12.418299Z"}},"outputs":[{"name":"stdout","text":"Total images: 20000\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import json\n\n# Load the JSON file from the Kaggle dataset directory\nwith open(\"path to the JSON file\", \"r\") as f:\n    data = json.load(f)\n\nprint(f\"Total entries: {len(data)}\")\n\n# Example: Access product data using an image_id\nsample_id = list(data.keys())[0]\nprint(\"Sample image_id:\", sample_id)\nprint(\"Associated product data:\", data[sample_id])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:57:14.995988Z","iopub.execute_input":"2025-05-04T16:57:14.996347Z","iopub.status.idle":"2025-05-04T16:59:04.373832Z","shell.execute_reply.started":"2025-05-04T16:57:14.996323Z","shell.execute_reply":"2025-05-04T16:59:04.372727Z"}},"outputs":[{"name":"stdout","text":"Total entries: 398170\nSample image_id: 81iZlv3bjpL\nAssociated product data: {'brand': [{'language_tag': 'en_GB', 'value': 'find.'}], 'item_id': 'B06X9WQGQP', 'item_name': [{'language_tag': 'en_GB', 'value': 'find. Women’s Ari Heeled Closed-Toe Heels'}], 'model_name': [{'language_tag': 'en_GB', 'value': 'Ari Heeled'}], 'model_year': [{'value': 2017}], 'product_type': [{'value': 'SHOES'}], 'style': [{'language_tag': 'en_GB', 'value': 'Closed-Toe Pumps'}], 'main_image_id': '81iZlv3bjpL', 'other_image_id': ['91mIRxgziUL', '91eqBkW06wL', 'A1BHZSKNbkL'], 'country': 'GB', 'marketplace': 'Amazon', 'domain_name': 'amazon.co.uk', 'node': [{'node_id': 1769851031, 'node_name': \"/Categories/Shoes/Women's Shoes/Court Shoes\"}]}\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"image_base_path = \"path for the small directory in the abo-small dataset\"\n\nsubset_df = df.iloc[7603:10903].reset_index(drop=True) # 3300","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:59:22.813015Z","iopub.execute_input":"2025-05-04T16:59:22.813352Z","iopub.status.idle":"2025-05-04T16:59:22.820405Z","shell.execute_reply.started":"2025-05-04T16:59:22.813325Z","shell.execute_reply":"2025-05-04T16:59:22.819021Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"sample_df = subset_df.sample(n=1000, random_state=7).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:59:24.533941Z","iopub.execute_input":"2025-05-04T16:59:24.534275Z","iopub.status.idle":"2025-05-04T16:59:24.551281Z","shell.execute_reply.started":"2025-05-04T16:59:24.534251Z","shell.execute_reply":"2025-05-04T16:59:24.550441Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import os\nimport re\nimport csv\nimport time\nimport json\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm import tqdm\n\n\ndef clean(text):\n    text = re.sub(r\"\\*+\", \"\", text)  # Remove asterisks used for markdown\n    text = re.sub(r\"\\n+\", \" \", text)  # Remove excessive newlines\n    text = re.sub(r\"\\s+\", \" \", text)  # Collapse all whitespace\n    text = re.sub(r\"^\\W+|\\W+$\", \"\", text)  # Remove non-alphanum from ends\n    return text.strip()\n\n\ndef extract_english_value(entry_list):\n    if not isinstance(entry_list, list):\n        return None\n    for entry in entry_list:\n        lang = entry.get(\"language_tag\", \"\")\n        if lang.startswith(\"en_\"):\n            return entry.get(\"value\")\n    return None\n\n\n\ndef get_metadata_string(metadata):\n    fields = [\n        \"brand\", \"bullet_point\", \"color\", \"fabric_type\", \"finish_type\", \"item_dimensions\",\n        \"item_keywords\", \"item_shape\", \"item_weight\", \"material\", \"model_name\",\n        \"pattern\", \"product_description\", \"style\"\n    ]\n\n    result = []\n    for field in fields:\n        value = metadata.get(field)\n        if value is None:\n            continue\n\n        if isinstance(value, list):\n            if isinstance(value[0], dict):\n                val = extract_english_value(value)\n                if val:\n                    result.append(f\"{field.replace('_', ' ').title()}: {val}\")\n            elif isinstance(value[0], str):\n                result.append(f\"{field.replace('_', ' ').title()}: {', '.join(value)}\")\n\n        elif isinstance(value, dict):  # item_dimensions\n            dims = []\n            for k, v in value.items():\n                norm = v.get(\"normalized_value\", {})\n                unit = norm.get(\"unit\", v.get(\"unit\"))\n                val = norm.get(\"value\", v.get(\"value\"))\n                dims.append(f\"{k.title()}: {val} {unit}\")\n            result.append(f\"{field.replace('_', ' ').title()}: {', '.join(dims)}\")\n\n    return \"\\n\".join(result)\n\n\n# Settings\noutput_csv = \"path to the putput file\"\npause_every_n_images = 4\nrate_limit_wait = 60\n# subset_df = sample_df.iloc[369:1000].reset_index(drop=True)\nsubset_df = sample_df\n\n# Ensure the CSV is reset at the start\nif os.path.exists(output_csv):\n    os.remove(output_csv)\n\nvqa_data = []\nimage_counter = 0\ndifficulties = [\"Easy\", \"Medium\", \"Hard\"]\n\nfor idx, row in tqdm(subset_df.iterrows(), total=len(subset_df)):\n    image_id = str(row[\"image_id\"])\n    image_path = os.path.join(image_base_path, row[\"path\"])\n\n    product_metadata = data.get(image_id)\n    if not product_metadata:\n        print(f\"[SKIP] No metadata found for image_id: {image_id}\")\n        continue\n\n    english_fields = {\n        \"item_name\": extract_english_value(product_metadata.get(\"item_name\", [])),\n        \"brand\": extract_english_value(product_metadata.get(\"brand\", [])),\n        \"bullet_point\": extract_english_value(product_metadata.get(\"bullet_point\", [])),\n        \"color\": extract_english_value(product_metadata.get(\"color\", [])),\n        \"style\": extract_english_value(product_metadata.get(\"style\", [])),\n    }\n\n    if not any(english_fields.values()):\n        lang_info = {}\n        for field in [\"item_name\", \"brand\", \"bullet_point\", \"color\", \"style\"]:\n            entries = product_metadata.get(field, [])\n            if isinstance(entries, list):\n                langs = [e.get(\"language_tag\", \"unknown\") for e in entries if isinstance(e, dict)]\n                if langs:\n                    lang_info[field] = langs\n        print(f\"[SKIP] No English entries for image_id: {image_id}. Found language tags: {json.dumps(lang_info)}\")\n        continue\n\n\n    metadata_str = get_metadata_string(product_metadata)\n    if not metadata_str:\n        print(f\"[SKIP] Metadata string is empty for image_id: {image_id}\")\n        continue\n\n    try:\n        image = Image.open(image_path)\n    except Exception as e:\n        print(f\"[SKIP] Failed to open image at path: {image_path} (image_id: {image_id}) | Error: {e}\")\n        continue\n\n    prompt = (\n        \"You are a Visual QA dataset assistant: for each image, generate exactly three \"\n        \"question-answer pairs, with a single word as the answer — in Easy (basic visual attributes), \"\n        \"Medium (advanced visual features), and Hard (logical inferences) difficulty—covering diverse types, \"\n        \"answerable solely from the image. Format: Question: ..., Answer: ...\\n\\n\"\n        f\"Product metadata:\\n{metadata_str}\"\n    )\n\n    response = model.generate_content([image, prompt])\n    text = response.text\n\n    pairs = re.findall(\n        r\"Question:\\s*(.*?)\\s*Answer:\\s*(.*?)(?=(?:Question:|$))\",\n        text, re.DOTALL\n    )\n\n    if not pairs:\n        print(f\"[SKIP] No valid QA pairs returned for image_id: {image_id}\")\n        continue\n\n    for i, (raw_q, raw_a) in enumerate(pairs):\n        q = clean(raw_q)\n        a = clean(raw_a)\n        q = re.sub(r\"\\b(?:Easy|Medium|Hard)\\s*:\\s*\", \"\", raw_q.strip(), flags=re.IGNORECASE)\n        a = re.sub(r\"\\b(?:Easy|Medium|Hard)\\s*:\\s*\", \"\", raw_a.strip(), flags=re.IGNORECASE)\n        if q and a:\n            difficulty = difficulties[i % 3]\n            vqa_data.append({\n                \"image_id\": image_id,\n                \"question\": clean(q),\n                \"answer\": clean(a),\n                \"difficulty\": difficulty\n            })\n\n    image_counter += 1\n\n    if image_counter % pause_every_n_images == 0 and vqa_data:\n        pd.DataFrame(vqa_data).to_csv(\n            output_csv, mode='a',\n            header=not os.path.exists(output_csv),\n            index=False, quoting=csv.QUOTE_ALL,\n            columns=[\"image_id\", \"question\", \"answer\", \"difficulty\"]\n        )\n        vqa_data = []\n        time.sleep(rate_limit_wait)\n\nif vqa_data:\n    pd.DataFrame(vqa_data).to_csv(\n        output_csv, mode='a',\n        header=not os.path.exists(output_csv),\n        index=False, quoting=csv.QUOTE_ALL,\n        columns=[\"image_id\", \"question\", \"answer\", \"difficulty\"]\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:59:25.917145Z","iopub.execute_input":"2025-05-04T16:59:25.917503Z","iopub.status.idle":"2025-05-04T17:22:21.266482Z","shell.execute_reply.started":"2025-05-04T16:59:25.917475Z","shell.execute_reply":"2025-05-04T17:22:21.264846Z"}},"outputs":[{"name":"stderr","text":"  0%|          | 3/631 [00:03<12:33,  1.20s/it]","output_type":"stream"},{"name":"stdout","text":"[SKIP] No English entries for image_id: 81lYWaNME9L. Found language tags: {\"item_name\": [\"es_ES\"], \"brand\": [\"es_ES\"], \"bullet_point\": [\"es_ES\", \"es_ES\", \"es_ES\", \"es_ES\", \"es_ES\"]}\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 11/631 [02:12<2:04:22, 12.04s/it]","output_type":"stream"},{"name":"stdout","text":"[SKIP] No English entries for image_id: 81WwmWOiYZL. Found language tags: {\"item_name\": [\"de_DE\"], \"brand\": [\"de_DE\"], \"bullet_point\": [\"de_DE\", \"de_DE\", \"de_DE\"]}\n","output_type":"stream"},{"name":"stderr","text":"  3%|▎         | 19/631 [04:21<2:54:51, 17.14s/it]","output_type":"stream"},{"name":"stdout","text":"[SKIP] No English entries for image_id: 81TLCuavmjL. Found language tags: {\"item_name\": [\"es_MX\"], \"brand\": [\"es_MX\"], \"bullet_point\": [\"es_MX\", \"es_MX\", \"es_MX\", \"es_MX\", \"es_MX\"]}\n","output_type":"stream"},{"name":"stderr","text":"  5%|▌         | 34/631 [07:38<1:32:14,  9.27s/it]","output_type":"stream"},{"name":"stdout","text":"[SKIP] No English entries for image_id: 81f2saaeH0L. Found language tags: {\"item_name\": [\"es_ES\", \"pt_PT\"], \"brand\": [\"es_ES\", \"pt_PT\"], \"bullet_point\": [\"es_ES\", \"es_ES\", \"es_ES\", \"es_ES\", \"es_ES\", \"pt_PT\", \"pt_PT\", \"pt_PT\", \"pt_PT\", \"pt_PT\"]}\n","output_type":"stream"},{"name":"stderr","text":"  7%|▋         | 45/631 [10:51<2:53:46, 17.79s/it]","output_type":"stream"},{"name":"stdout","text":"[SKIP] No English entries for image_id: 81MTAAuGkpL. Found language tags: {\"item_name\": [\"es_ES\"], \"brand\": [\"es_ES\"], \"bullet_point\": [\"es_ES\"], \"color\": [\"es_ES\"], \"style\": [\"es_ES\"]}\n","output_type":"stream"},{"name":"stderr","text":"  8%|▊         | 48/631 [10:54<1:17:03,  7.93s/it]","output_type":"stream"},{"name":"stdout","text":"[SKIP] No English entries for image_id: 81nfajljhKL. Found language tags: {\"item_name\": [\"sv_SE\"], \"brand\": [\"sv_SE\"], \"bullet_point\": [\"sv_SE\", \"sv_SE\", \"sv_SE\", \"sv_SE\"], \"color\": [\"sv_SE\"]}\n","output_type":"stream"},{"name":"stderr","text":"  8%|▊         | 53/631 [11:59<1:18:22,  8.14s/it]","output_type":"stream"},{"name":"stdout","text":"[SKIP] No English entries for image_id: 81i5KiO116L. Found language tags: {\"item_name\": [\"nl_NL\"], \"brand\": [\"nl_NL\"], \"bullet_point\": [\"nl_NL\", \"nl_NL\", \"nl_NL\", \"nl_NL\", \"nl_NL\"]}\n","output_type":"stream"},{"name":"stderr","text":" 11%|█         | 70/631 [16:18<1:26:07,  9.21s/it]","output_type":"stream"},{"name":"stdout","text":"[SKIP] No English entries for image_id: 81UYKzpBqjL. Found language tags: {\"item_name\": [\"fr_FR\"], \"brand\": [\"fr_FR\"], \"bullet_point\": [\"fr_FR\", \"fr_FR\", \"fr_FR\", \"fr_FR\", \"fr_FR\", \"fr_FR\", \"fr_FR\", \"fr_FR\"], \"style\": [\"fr_FR\"]}\n[SKIP] No English entries for image_id: 81gSlLdFSdL. Found language tags: {\"item_name\": [\"ja_JP\"], \"brand\": [\"ja_JP\"], \"color\": [\"ja_JP\"], \"style\": [\"ja_JP\"]}\n[SKIP] No English entries for image_id: 81ULALRBCVL. Found language tags: {\"item_name\": [\"sv_SE\"], \"brand\": [\"sv_SE\"], \"bullet_point\": [\"sv_SE\", \"sv_SE\", \"sv_SE\", \"sv_SE\", \"sv_SE\"], \"color\": [\"sv_SE\"]}\n[SKIP] No English entries for image_id: 81aWA3hS+vL. Found language tags: {\"item_name\": [\"de_DE\"], \"brand\": [\"de_DE\"], \"bullet_point\": [\"de_DE\", \"de_DE\", \"de_DE\", \"de_DE\", \"de_DE\", \"de_DE\", \"de_DE\", \"de_DE\", \"de_DE\", \"de_DE\"]}\n","output_type":"stream"},{"name":"stderr","text":" 12%|█▏        | 76/631 [17:20<1:29:44,  9.70s/it]","output_type":"stream"},{"name":"stdout","text":"[SKIP] No English entries for image_id: 81DCCQDxXGL. Found language tags: {\"item_name\": [\"tr_TR\"], \"brand\": [\"tr_TR\"], \"bullet_point\": [\"tr_TR\", \"tr_TR\", \"tr_TR\", \"tr_TR\"], \"color\": [\"tr_TR\"]}\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 81/631 [18:25<2:05:01, 13.64s/it]","output_type":"stream"},{"name":"stdout","text":"[SKIP] No English entries for image_id: 81l9V8UkHbL. Found language tags: {\"item_name\": [\"sv_SE\"], \"brand\": [\"sv_SE\"], \"style\": [\"sv_SE\"]}\n","output_type":"stream"},{"name":"stderr","text":" 16%|█▌        | 100/631 [22:55<2:01:42, 13.75s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/1871843308.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    160\u001b[0m         )\n\u001b[1;32m    161\u001b[0m         \u001b[0mvqa_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate_limit_wait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvqa_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}